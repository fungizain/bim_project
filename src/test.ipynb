{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5769f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def get_images_base64(chunks):\n",
    "    images_b64 = []\n",
    "    for chunk in chunks:\n",
    "        if \"CompositeElement\" in str(type(chunk)):\n",
    "            chunk_els = chunk.metadata.orig_elements\n",
    "            for el in chunk_els:\n",
    "                if \"Image\" in str(type(el)):\n",
    "                    images_b64.append(el.metadata.image_base64)\n",
    "    return images_b64\n",
    "\n",
    "images = get_images_base64(chunks)\n",
    "\n",
    "def display_base64_image(base64_code):\n",
    "    # Decode the base64 string to binary\n",
    "    image_data = base64.b64decode(base64_code)\n",
    "    # Display the image\n",
    "    display(Image(data=image_data))\n",
    "\n",
    "display_base64_image(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9e9f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import UPLOAD_PATH\n",
    "from src.pdf_service import load_pdf\n",
    "\n",
    "filenames = [\"Testing File Simple.pdf\", \"Test Case 1_E1_CHR.pdf\", \"Test Case 2_88-111.pdf\"]\n",
    "pdf_file = UPLOAD_PATH / filenames[1]\n",
    "chunks = load_pdf(pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "312502fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<answer>KT-EMSDN-NA-000-LAE-ELL-0015</answer>\n",
      "File: Testing File Simple.pdf, Page: 2-2, Accuracy: 100%\n",
      "Answer:\n",
      "<answer>kt-emsdn-000-la-ell-0015</answer>\n",
      "File: Testing File Simple.pdf, Page: 1-1, Accuracy: 100%\n",
      "Answer:\n",
      "<answer>kt-emsdn-000-la-ell-0015</answer>\n",
      "File: Testing File Simple.pdf, Page: 2-\n"
     ]
    }
   ],
   "source": [
    "from src.chroma_service import prepare_prompt_from_query\n",
    "from src.model_service import qa_pipeline\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are a precise document QA assistant. Read the provided document context and answer the question.\n",
    "\n",
    "Follow these rules step by step:\n",
    "1. Ensure factual accuracy. Do not hallucinate.\n",
    "2. Remove redundant or irrelevant information.\n",
    "3. Provide at most 3 unique candidate answers. Place the most suitable one at the top.\n",
    "4. If the question specifies a manufacturer and model number, try to match them explicitly.\n",
    "5. Do not repeat identical answers from different chunks. Deduplicate before presenting.\n",
    "6. After each answer, append the exact source location and accuracy percentage in this format:\n",
    "   \"Answer: <answer>, File: <filename>, Page: <page-range>, Accuracy: <percentage>%\"\n",
    "\n",
    "Question: {query}\n",
    "Document Context:\n",
    "{context}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "query = \"What is the asset code?\"\n",
    "prompt, hits = prepare_prompt_from_query(query, PROMPT_TEMPLATE)\n",
    "\n",
    "generated_ids = qa_pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=128,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "answer = generated_ids[0][\"generated_text\"].strip()\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2130e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\n"
     ]
    }
   ],
   "source": [
    "from openai_harmony import (\n",
    "    Conversation,\n",
    "    DeveloperContent,\n",
    "    HarmonyEncodingName,\n",
    "    Message,\n",
    "    Role,\n",
    "    SystemContent,\n",
    "    load_harmony_encoding,\n",
    "    ReasoningEffort\n",
    ")\n",
    "\n",
    "msg = Message.from_role_and_content(Role.USER, \"abc\")\n",
    "msg.with_channel\n",
    "print(msg.channel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bim-project-py3.12 (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
